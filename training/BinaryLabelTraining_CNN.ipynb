{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data pre-processing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Conv1D, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# To save model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "file_path = \"../data/norm_dataset.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Client agrees to pay to Company the sum of $5,000 (the “Contract Price”) to design and develop a website for Client (the “Client Website”) in accordance with the accompanying Scope of Work, attached to this Agreement as Exhibit A.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company will use its best efforts to deliver the Client Website in the time frame specified in the Scope of Work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All written content submitted by Client for use in the Client Website must be typewritten, proofread and delivered to Company in the body of an email message or as a Microsoft Word electronic document or plaint text electronic document.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is Client’s sole responsibility to check the accuracy of the written content and correct any errors prior to submission for final publication.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Client further agrees that Company may use and display the graphics and other web design elements of Client’s website as examples of Company website design and development work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                           text  \\\n",
       "0        Client agrees to pay to Company the sum of $5,000 (the “Contract Price”) to design and develop a website for Client (the “Client Website”) in accordance with the accompanying Scope of Work, attached to this Agreement as Exhibit A.   \n",
       "1                                                                                                                             Company will use its best efforts to deliver the Client Website in the time frame specified in the Scope of Work.   \n",
       "2  All written content submitted by Client for use in the Client Website must be typewritten, proofread and delivered to Company in the body of an email message or as a Microsoft Word electronic document or plaint text electronic document.   \n",
       "3                                                                                             It is Client’s sole responsibility to check the accuracy of the written content and correct any errors prior to submission for final publication.   \n",
       "4                                                             Client further agrees that Company may use and display the graphics and other web design elements of Client’s website as examples of Company website design and development work.   \n",
       "\n",
       "   norm  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data head and extend the max column width\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "361    1\n",
       "362    1\n",
       "363    1\n",
       "364    1\n",
       "365    1\n",
       "Name: norm, Length: 360, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign norms to target variable. Values already numeric\n",
    "y = df['norm']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard keras pre-processing\n",
    "maxlen = 200 # Highest word count is 555 and mean is 43\n",
    "max_words = 2000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df.text)\n",
    "\n",
    "# Functions to transform text to feature_vectors \n",
    "def get_features(text_series):\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 200) (360,)\n"
     ]
    }
   ],
   "source": [
    "# Call function to create features 'X'\n",
    "X = get_features(df.text)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# law2vec 100 dimensional word embeddings\n",
    "from numpy import array, asarray, zeros\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "law2vec_file = open('./Law2Vec.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "# Parse each line and store word-vector pairs in a dictionary\n",
    "for line in law2vec_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "law2vec_file.close()\n",
    "\n",
    "# Each row corresponds to a word with its 100 dimensional word vector\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "\n",
    "# tokenizer.word_index is a list of (word, id) tuples\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 100)          230300    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200, 100)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 193, 300)          240300    \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 300)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 470,901\n",
      "Trainable params: 240,601\n",
      "Non-trainable params: 230,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modelling - Convolutional Neural Network\n",
    "\n",
    "filter_length = 300\n",
    "num_classes = 1 # binary problem\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, kernel_size=8, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.5382WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 2s 83ms/step - loss: 0.7131 - accuracy: 0.5382 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.8507WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4836 - accuracy: 0.8507 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.9410WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3545 - accuracy: 0.9410 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2810 - accuracy: 0.9688WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.2810 - accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9792WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.2179 - accuracy: 0.9792 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9896WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1643 - accuracy: 0.9896 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1345 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9965WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1088 - accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.0832 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.0684 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0565 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0445 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0403 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0320 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0283 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0249 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0214 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.0180 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0166 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0144 - accuracy: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(), \n",
    "    EarlyStopping(patience=4), \n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2614 - accuracy: 0.8750\n",
      "3/3 [==============================] - 0s 19ms/step\n",
      "loss: 0.261433482170105\n",
      "accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n",
      "[[0.96828336]]\n",
      "[[1]]\n",
      "Norm\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "x = [\"Each Party shall return to the other all of the other’s Confidential Information and any other material, information or samples relating to the Product which have been provided or made available to the other and shall not retain any copies and the Parties further agree not to make any further use of each other’s Confidential Information or any other information, data or samples relating to the Product provided or made available by the other Party, except as necessary to comply with its statutory, regulatory or licensing obligations; provided, however, that Kitov may retain such material, information and/or samples relating to the Product as may be necessary for Kitov to continue to sell the Product as permitted by Section ​5.4.4 below, following which, Kitov shall refrain from making any further use of Dexcel’s Confidential Information or any other information, data or samples and shall return any remaining Confidential Information and material, information or samples relating to the Product.\"]\n",
    "xt = get_features(x)\n",
    "prediction = model.predict(xt)\n",
    "probas = (prediction > 0.5).astype(int)\n",
    "\n",
    "if probas == [1]:\n",
    "    tag = 'Norm'\n",
    "else:\n",
    "    tag = 'Non-norm'\n",
    "\n",
    "print(prediction)\n",
    "print(probas)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/BinaryLabelTokenizer.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tokenizer\n",
    "joblib.dump(tokenizer, '../models/BinaryLabelTokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a6abc740-0689-48d7-98fe-d7d5b2c7c885/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a6abc740-0689-48d7-98fe-d7d5b2c7c885/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/BinaryLabelModel_CNN.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, '../models/BinaryLabelModel_CNN.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
