{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data pre-processing\n",
    "from ast import literal_eval\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Conv1D, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import label_ranking_average_precision_score, label_ranking_loss, average_precision_score\n",
    "\n",
    "# To save model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "file_path = \"../data/preprocessed_data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>we will issue a certificate of completion for each manager trainee who completes the initial training program we require to our satisfaction each such person will be referred to a a certified manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>elephant talk bear the risk of and shall indemnify against high usage fraud and bed of it elephant talk customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>subject to the term and condition of this agreement aimmune shall be responsible for the development of the product a set forth herein aimmune itself or with or through it affiliate and sublicensees shall use commercially reasonable effort to perform the development activity for the product to i achieve the development milestone set forth in section and ii obtain regulatory approval for the product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>ediets shall ensure that the ediets content complies with editorial guideline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>auriemma will participate in one recording session annually during the service period of not more than two hour not including travel time to record a radio advertising spot at a date and location to be mutually agreed upon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag  \\\n",
       "0  ['obligation']   \n",
       "1  ['obligation']   \n",
       "2  ['obligation']   \n",
       "3  ['obligation']   \n",
       "4  ['obligation']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                            sentence  \n",
       "0                                                                                                                                                                                                            we will issue a certificate of completion for each manager trainee who completes the initial training program we require to our satisfaction each such person will be referred to a a certified manager  \n",
       "1                                                                                                                                                                                                                                                                                                   elephant talk bear the risk of and shall indemnify against high usage fraud and bed of it elephant talk customer  \n",
       "2  subject to the term and condition of this agreement aimmune shall be responsible for the development of the product a set forth herein aimmune itself or with or through it affiliate and sublicensees shall use commercially reasonable effort to perform the development activity for the product to i achieve the development milestone set forth in section and ii obtain regulatory approval for the product  \n",
       "3                                                                                                                                                                                                                                                                                                                                      ediets shall ensure that the ediets content complies with editorial guideline  \n",
       "4                                                                                                                                                                                     auriemma will participate in one recording session annually during the service period of not more than two hour not including travel time to record a radio advertising spot at a date and location to be mutually agreed upon  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data head and extend the max column width\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tags from strings to lists\n",
    "df['tag'] = df['tag'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode tags 'y'\n",
    "y = df['tag']\n",
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = list(df.sentence)\n",
    "y = multilabel.transform(df.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard keras pre-processing\n",
    "maxlen = 200 # Highest word count is 691 and mean is 52; however, 691 is an outlier\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Padding - sequences with word count less than 200 are added\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((757, 200), (757, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word embeddings using law2vec\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "law2vec_file = open('./Law2Vec.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "# Parse each line and store word-vector pairs in a dictionary\n",
    "for line in law2vec_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "law2vec_file.close()\n",
    "\n",
    "# Each row corresponds to a word with its 100-d word vector\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "\n",
    "# tokenizer.word_index is a list of (word, id) tuples\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 200, 100)          271900    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 128)               117248    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 389,535\n",
      "Trainable params: 117,635\n",
      "Non-trainable params: 271,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build RNN model with 128 LSTM units\n",
    "deep_inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False, mask_zero=True)(deep_inputs)\n",
    "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
    "dense_layer_1 = Dense(3, activation='sigmoid')(LSTM_Layer_1)\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['binary_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 13s 401ms/step - loss: 0.6657 - binary_accuracy: 0.6143 - val_loss: 0.6629 - val_binary_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 5s 262ms/step - loss: 0.6343 - binary_accuracy: 0.6419 - val_loss: 0.6157 - val_binary_accuracy: 0.6557 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 6s 304ms/step - loss: 0.5812 - binary_accuracy: 0.6931 - val_loss: 0.5952 - val_binary_accuracy: 0.6798 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 6s 332ms/step - loss: 0.5487 - binary_accuracy: 0.7273 - val_loss: 0.6151 - val_binary_accuracy: 0.6557 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 6s 321ms/step - loss: 0.5162 - binary_accuracy: 0.7460 - val_loss: 0.5875 - val_binary_accuracy: 0.6908 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 8s 422ms/step - loss: 0.5711 - binary_accuracy: 0.7152 - val_loss: 0.6252 - val_binary_accuracy: 0.6404 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 9s 463ms/step - loss: 0.5377 - binary_accuracy: 0.7394 - val_loss: 0.6435 - val_binary_accuracy: 0.6404 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 8s 404ms/step - loss: 0.5197 - binary_accuracy: 0.7587 - val_loss: 0.5887 - val_binary_accuracy: 0.6601 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 8s 452ms/step - loss: 0.5266 - binary_accuracy: 0.7350 - val_loss: 0.6100 - val_binary_accuracy: 0.6645 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(), \n",
    "    EarlyStopping(patience=4)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 100ms/step - loss: 0.5916 - binary_accuracy: 0.6649\n",
      "loss: 0.5916264057159424\n",
      "binary_accuracy: 0.6649122834205627\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 99ms/step\n",
      "LRAP: 0.76\n",
      "Ranking Loss: 0.31\n",
      "Precision Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Loss and precision score\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"LRAP: {:.2}\".format(label_ranking_average_precision_score(y_test,y_pred)))\n",
    "print(\"Ranking Loss: {:.2}\".format(label_ranking_loss(y_test,y_pred)))\n",
    "print(\"Precision Score: {:.2}\".format(average_precision_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# x = [\"Each Party shall return to the other all of the other’s Confidential Information and any other material, information or samples relating to the Product which have been provided or made available to the other and shall not retain any copies and the Parties further agree not to make any further use of each other’s Confidential Information or any other information, data or samples relating to the Product provided or made available by the other Party, except as necessary to comply with its statutory, regulatory or licensing obligations; provided, however, that Kitov may retain such material, information and/or samples relating to the Product as may be necessary for Kitov to continue to sell the Product as permitted by Section ​5.4.4 below, following which, Kitov shall refrain from making any further use of Dexcel’s Confidential Information or any other information, data or samples and shall return any remaining Confidential Information and material, information or samples relating to the Product.\"]\n",
    "# prediction = model.predict(x)\n",
    "# # probas = np.array(prediction)\n",
    "# # labels = (probas > 0.5).astype(np.int)\n",
    "\n",
    "# # tags = multilabel.inverse_transform(labels)\n",
    "\n",
    "# print(prediction)\n",
    "# print(labels)\n",
    "# print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://14e11479-1535-4174-b1d6-03d8781bc0a7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://14e11479-1535-4174-b1d6-03d8781bc0a7/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/MultiLabelModel_LSTM.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, '../models/MultiLabelModel_LSTM.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
